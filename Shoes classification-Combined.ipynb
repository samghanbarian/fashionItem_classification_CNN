{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arsene\\anaconda3\\lib\\site-packages\\requests\\__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.8) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data\n",
    "train_data = np.load(r'datasets/Shoes - All - Train.npz')\n",
    "val_data = np.load(r'datasets/Shoes - All - Validation.npz')\n",
    "test_data = np.load(r'datasets/Shoes - All - Test.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = train_data['images'], train_data['labels']\n",
    "val_images, val_labels = val_data['images'], val_data['labels']\n",
    "test_images, test_labels = test_data['images'], test_data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling\n",
    "train_images = train_images/255.\n",
    "val_images = val_images/255.\n",
    "test_images = test_images/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constant definition\n",
    "NUM_EPOCHS = 11\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparam definition\n",
    "HP_FILTER_SIZE = hp.HParam('filter_size', hp.Discrete([5,7]))\n",
    "HP_NUM_FILTER = hp.HParam('filters_number', hp.Discrete([96,128]))\n",
    "HP_DENSE_SIZE = hp.HParam('dense_size', hp.Discrete([512,1024]))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "with tf.summary.create_file_writer(r'D:/sam/Logs/Model 5/hparam_tuning/').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams= [HP_FILTER_SIZE,HP_NUM_FILTER,HP_DENSE_SIZE],\n",
    "        metrics = [hp.Metric(METRIC_ACCURACY,display_name='accuracy')]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model definition and training\n",
    "def train_test_model(hparams,session_num):\n",
    "    \n",
    "    #model outline\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(hparams[HP_NUM_FILTER],hparams[HP_FILTER_SIZE], activation='relu', input_shape=(120,90,3)),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Conv2D(hparams[HP_NUM_FILTER],5,activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(hparams[HP_DENSE_SIZE], activation='relu'),\n",
    "        tf.keras.layers.Dense(11)\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss= loss_fn, metrics=['accuracy'])\n",
    "    \n",
    "    #defining the logging dir\n",
    "    log_dir = 'D:/sam/Logs/Model 5/fit/'+'run-{}'.format(session_num)\n",
    "    \n",
    "    def plot_confusion_matrix(cm, class_names):\n",
    "        figure = plt.figure(figsize=(12, 12))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title(\"Confusion matrix\")\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(class_names))\n",
    "        plt.xticks(tick_marks, class_names, rotation=45)\n",
    "        plt.yticks(tick_marks, class_names)\n",
    "\n",
    "        # Normalize the confusion matrix\n",
    "        cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "        # Use white text if squares are dark; otherwise black.\n",
    "        threshold = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label') \n",
    "        return figure\n",
    "\n",
    "    def plot_to_image(figure):\n",
    "    \n",
    "        #save the plot to a png in memory\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "    \n",
    "        #closing the figure to prevent from displaying in the notebook\n",
    "        plt.close(figure)\n",
    "    \n",
    "        buf.seek(0)\n",
    "    \n",
    "        image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    \n",
    "        #add the batch dimension\n",
    "        image = tf.expand_dims(image, 0)\n",
    "    \n",
    "        return image\n",
    "\n",
    "    #file writer for logging cofusion matrix\n",
    "    file_writer_cm = tf.summary.create_file_writer(log_dir + '/cm')\n",
    "    \n",
    "    def log_confusion_matrix(epoch, logs):\n",
    "    #predict values for validation set\n",
    "        test_pred_r = model.predict(val_images)\n",
    "        test_pred = np.argmax(test_pred_r, axis=1)\n",
    "    \n",
    "        cm = sklearn.metrics.confusion_matrix(val_labels, test_pred)\n",
    "    \n",
    "        figure = plot_confusion_matrix(cm, class_names=[ 'Male Boots', 'Male Trainers/sneakers','Male Sandals',\n",
    "                                                        'Male Formal shoes', 'Male Other','Female Boots', 'Female Ballerina shoes','Female Sneakers/trainesr',\n",
    "                                                        'Female Sandals','Female High heels','Female Other'])\n",
    "        cm_image = plot_to_image(figure)\n",
    "    \n",
    "        #log the confusion matrix as image summary\n",
    "        with file_writer_cm.as_default():\n",
    "            tf.summary.image('Confusion Matrix', cm_image, step=epoch)\n",
    "            \n",
    "    \n",
    "    \n",
    "    #defining callbacks\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq = 1, profile_batch = 0)\n",
    "    cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end= log_confusion_matrix)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        mode = 'auto',\n",
    "        verbose=0,\n",
    "        patience = 2,\n",
    "        min_delta = 0,\n",
    "        restore_best_weights= True\n",
    "    )\n",
    "\n",
    "    \n",
    "    #training the model\n",
    "    model.fit(\n",
    "        train_images,\n",
    "        train_labels,\n",
    "        validation_data= (val_images,val_labels),\n",
    "        verbose=2,\n",
    "        epochs= NUM_EPOCHS,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        callbacks=[tensorboard_callback,cm_callback,early_stopping]\n",
    "        \n",
    "    )\n",
    "    \n",
    "    #model performance evaluation\n",
    "    _, accuracy = model.evaluate(val_images,val_labels)\n",
    "    \n",
    "    #saving the model\n",
    "    model.save(r'D:/sam/saved Models/Model 5/Run-{}'.format(session_num))\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logging the result function\n",
    "def run(log_dir, hparams, session_num):\n",
    "    \n",
    "    with tf.summary.create_file_writer(log_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        accuracy = train_test_model(hparams, session_num)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Starting trial : run-1\n",
      "{'filter_size': 5, 'filters_number': 96, 'dense_size': 512}\n",
      "Epoch 1/11\n",
      "78/78 - 140s - loss: 1.6918 - accuracy: 0.4882 - val_loss: 1.3169 - val_accuracy: 0.5267 - 140s/epoch - 2s/step\n",
      "Epoch 2/11\n",
      "78/78 - 136s - loss: 0.9904 - accuracy: 0.6647 - val_loss: 1.1173 - val_accuracy: 0.6591 - 136s/epoch - 2s/step\n",
      "Epoch 3/11\n",
      "78/78 - 136s - loss: 0.8521 - accuracy: 0.7096 - val_loss: 1.0843 - val_accuracy: 0.6527 - 136s/epoch - 2s/step\n",
      "Epoch 4/11\n",
      "78/78 - 141s - loss: 0.8370 - accuracy: 0.7072 - val_loss: 0.9627 - val_accuracy: 0.7108 - 141s/epoch - 2s/step\n",
      "Epoch 5/11\n",
      "78/78 - 133s - loss: 0.6298 - accuracy: 0.7766 - val_loss: 1.0718 - val_accuracy: 0.6640 - 133s/epoch - 2s/step\n",
      "Epoch 6/11\n",
      "78/78 - 129s - loss: 0.5383 - accuracy: 0.8078 - val_loss: 1.0070 - val_accuracy: 0.6882 - 129s/epoch - 2s/step\n",
      "20/20 [==============================] - 5s 237ms/step - loss: 0.9627 - accuracy: 0.7108\n",
      "INFO:tensorflow:Assets written to: D:/sam/saved Models/Model 5/Run-1\\assets\n",
      "---- Starting trial : run-2\n",
      "{'filter_size': 5, 'filters_number': 96, 'dense_size': 1024}\n",
      "Epoch 1/11\n",
      "78/78 - 166s - loss: 1.8822 - accuracy: 0.4646 - val_loss: 1.2038 - val_accuracy: 0.6236 - 166s/epoch - 2s/step\n",
      "Epoch 2/11\n",
      "78/78 - 163s - loss: 0.9816 - accuracy: 0.6681 - val_loss: 1.0729 - val_accuracy: 0.6656 - 163s/epoch - 2s/step\n",
      "Epoch 3/11\n",
      "78/78 - 156s - loss: 0.7495 - accuracy: 0.7397 - val_loss: 0.8668 - val_accuracy: 0.6995 - 156s/epoch - 2s/step\n",
      "Epoch 4/11\n",
      "78/78 - 154s - loss: 0.6642 - accuracy: 0.7647 - val_loss: 0.8485 - val_accuracy: 0.7157 - 154s/epoch - 2s/step\n",
      "Epoch 5/11\n",
      "78/78 - 154s - loss: 0.5613 - accuracy: 0.7895 - val_loss: 0.7981 - val_accuracy: 0.7157 - 154s/epoch - 2s/step\n",
      "Epoch 6/11\n",
      "78/78 - 181s - loss: 0.4604 - accuracy: 0.8310 - val_loss: 0.7953 - val_accuracy: 0.7270 - 181s/epoch - 2s/step\n",
      "Epoch 7/11\n",
      "78/78 - 161s - loss: 0.4057 - accuracy: 0.8564 - val_loss: 0.9253 - val_accuracy: 0.7399 - 161s/epoch - 2s/step\n",
      "Epoch 8/11\n",
      "78/78 - 169s - loss: 0.3727 - accuracy: 0.8643 - val_loss: 0.9083 - val_accuracy: 0.7512 - 169s/epoch - 2s/step\n",
      "20/20 [==============================] - 20s 197ms/step - loss: 0.7953 - accuracy: 0.7270\n",
      "INFO:tensorflow:Assets written to: D:/sam/saved Models/Model 5/Run-2\\assets\n",
      "---- Starting trial : run-3\n",
      "{'filter_size': 5, 'filters_number': 128, 'dense_size': 512}\n",
      "Epoch 1/11\n",
      "78/78 - 194s - loss: 2.0034 - accuracy: 0.4204 - val_loss: 1.6371 - val_accuracy: 0.4927 - 194s/epoch - 2s/step\n",
      "Epoch 2/11\n",
      "78/78 - 196s - loss: 1.1767 - accuracy: 0.6163 - val_loss: 1.0958 - val_accuracy: 0.6478 - 196s/epoch - 3s/step\n",
      "Epoch 3/11\n",
      "78/78 - 192s - loss: 1.1169 - accuracy: 0.6400 - val_loss: 1.2307 - val_accuracy: 0.6365 - 192s/epoch - 2s/step\n",
      "Epoch 4/11\n",
      "78/78 - 194s - loss: 0.8635 - accuracy: 0.7116 - val_loss: 0.9334 - val_accuracy: 0.7027 - 194s/epoch - 2s/step\n",
      "Epoch 5/11\n",
      "78/78 - 191s - loss: 0.8903 - accuracy: 0.6891 - val_loss: 0.9746 - val_accuracy: 0.6688 - 191s/epoch - 2s/step\n",
      "Epoch 6/11\n",
      "78/78 - 196s - loss: 0.7596 - accuracy: 0.7372 - val_loss: 0.9888 - val_accuracy: 0.6834 - 196s/epoch - 3s/step\n",
      "20/20 [==============================] - 6s 285ms/step - loss: 0.9334 - accuracy: 0.7027\n",
      "INFO:tensorflow:Assets written to: D:/sam/saved Models/Model 5/Run-3\\assets\n",
      "---- Starting trial : run-4\n",
      "{'filter_size': 5, 'filters_number': 128, 'dense_size': 1024}\n",
      "Epoch 1/11\n",
      "78/78 - 328s - loss: 1.8342 - accuracy: 0.4856 - val_loss: 1.1176 - val_accuracy: 0.6430 - 328s/epoch - 4s/step\n",
      "Epoch 2/11\n",
      "78/78 - 442s - loss: 0.9099 - accuracy: 0.6870 - val_loss: 0.9313 - val_accuracy: 0.6672 - 442s/epoch - 6s/step\n",
      "Epoch 3/11\n",
      "78/78 - 498s - loss: 0.7269 - accuracy: 0.7497 - val_loss: 0.7546 - val_accuracy: 0.7480 - 498s/epoch - 6s/step\n",
      "Epoch 4/11\n",
      "78/78 - 501s - loss: 0.6031 - accuracy: 0.7852 - val_loss: 0.7887 - val_accuracy: 0.7383 - 501s/epoch - 6s/step\n",
      "Epoch 5/11\n",
      "78/78 - 474s - loss: 0.5072 - accuracy: 0.8135 - val_loss: 0.7311 - val_accuracy: 0.7625 - 474s/epoch - 6s/step\n",
      "Epoch 6/11\n",
      "78/78 - 658s - loss: 0.4181 - accuracy: 0.8451 - val_loss: 0.8361 - val_accuracy: 0.7561 - 658s/epoch - 8s/step\n",
      "Epoch 7/11\n",
      "78/78 - 502s - loss: 0.3697 - accuracy: 0.8653 - val_loss: 0.8005 - val_accuracy: 0.7787 - 502s/epoch - 6s/step\n",
      "20/20 [==============================] - 33s 307ms/step - loss: 0.7311 - accuracy: 0.7625\n",
      "INFO:tensorflow:Assets written to: D:/sam/saved Models/Model 5/Run-4\\assets\n",
      "---- Starting trial : run-5\n",
      "{'filter_size': 7, 'filters_number': 96, 'dense_size': 512}\n",
      "Epoch 1/11\n",
      "78/78 - 133s - loss: 1.9274 - accuracy: 0.4206 - val_loss: 1.3936 - val_accuracy: 0.5186 - 133s/epoch - 2s/step\n",
      "Epoch 2/11\n",
      "78/78 - 133s - loss: 1.0298 - accuracy: 0.6606 - val_loss: 1.1152 - val_accuracy: 0.6204 - 133s/epoch - 2s/step\n",
      "Epoch 3/11\n",
      "78/78 - 133s - loss: 0.8767 - accuracy: 0.7092 - val_loss: 0.8853 - val_accuracy: 0.6995 - 133s/epoch - 2s/step\n",
      "Epoch 4/11\n",
      "78/78 - 131s - loss: 0.7193 - accuracy: 0.7491 - val_loss: 0.8595 - val_accuracy: 0.7044 - 131s/epoch - 2s/step\n",
      "Epoch 5/11\n",
      "78/78 - 130s - loss: 0.6608 - accuracy: 0.7639 - val_loss: 0.8583 - val_accuracy: 0.7141 - 130s/epoch - 2s/step\n",
      "Epoch 6/11\n",
      "78/78 - 131s - loss: 0.5545 - accuracy: 0.7977 - val_loss: 0.8100 - val_accuracy: 0.7221 - 131s/epoch - 2s/step\n",
      "Epoch 7/11\n",
      "78/78 - 132s - loss: 0.5061 - accuracy: 0.8201 - val_loss: 0.8195 - val_accuracy: 0.7383 - 132s/epoch - 2s/step\n",
      "Epoch 8/11\n",
      "78/78 - 132s - loss: 0.4713 - accuracy: 0.8324 - val_loss: 0.8553 - val_accuracy: 0.7464 - 132s/epoch - 2s/step\n",
      "20/20 [==============================] - 4s 193ms/step - loss: 0.8100 - accuracy: 0.7221\n",
      "INFO:tensorflow:Assets written to: D:/sam/saved Models/Model 5/Run-5\\assets\n",
      "---- Starting trial : run-6\n",
      "{'filter_size': 7, 'filters_number': 96, 'dense_size': 1024}\n",
      "Epoch 1/11\n",
      "78/78 - 168s - loss: 1.8374 - accuracy: 0.4610 - val_loss: 1.4425 - val_accuracy: 0.5767 - 168s/epoch - 2s/step\n",
      "Epoch 2/11\n",
      "78/78 - 159s - loss: 1.1153 - accuracy: 0.6403 - val_loss: 1.1274 - val_accuracy: 0.6090 - 159s/epoch - 2s/step\n",
      "Epoch 3/11\n",
      "78/78 - 171s - loss: 0.8704 - accuracy: 0.6975 - val_loss: 0.9350 - val_accuracy: 0.7092 - 171s/epoch - 2s/step\n",
      "Epoch 4/11\n",
      "78/78 - 167s - loss: 0.7603 - accuracy: 0.7391 - val_loss: 0.9752 - val_accuracy: 0.6882 - 167s/epoch - 2s/step\n",
      "Epoch 5/11\n",
      "78/78 - 171s - loss: 0.6604 - accuracy: 0.7667 - val_loss: 0.9980 - val_accuracy: 0.7011 - 171s/epoch - 2s/step\n",
      "20/20 [==============================] - 17s 220ms/step - loss: 0.9350 - accuracy: 0.7092\n",
      "INFO:tensorflow:Assets written to: D:/sam/saved Models/Model 5/Run-6\\assets\n",
      "---- Starting trial : run-7\n",
      "{'filter_size': 7, 'filters_number': 128, 'dense_size': 512}\n",
      "Epoch 1/11\n",
      "78/78 - 193s - loss: 1.9435 - accuracy: 0.4051 - val_loss: 1.3570 - val_accuracy: 0.5428 - 193s/epoch - 2s/step\n",
      "Epoch 2/11\n",
      "78/78 - 194s - loss: 1.0873 - accuracy: 0.6354 - val_loss: 1.1643 - val_accuracy: 0.6204 - 194s/epoch - 2s/step\n",
      "Epoch 3/11\n",
      "78/78 - 195s - loss: 0.9776 - accuracy: 0.6705 - val_loss: 1.0446 - val_accuracy: 0.6252 - 195s/epoch - 3s/step\n",
      "Epoch 4/11\n",
      "78/78 - 194s - loss: 0.8549 - accuracy: 0.7126 - val_loss: 0.9469 - val_accuracy: 0.6963 - 194s/epoch - 2s/step\n",
      "Epoch 5/11\n",
      "78/78 - 193s - loss: 0.7237 - accuracy: 0.7427 - val_loss: 0.8969 - val_accuracy: 0.7141 - 193s/epoch - 2s/step\n",
      "Epoch 6/11\n",
      "78/78 - 192s - loss: 0.6411 - accuracy: 0.7701 - val_loss: 0.8072 - val_accuracy: 0.7399 - 192s/epoch - 2s/step\n",
      "Epoch 7/11\n",
      "78/78 - 192s - loss: 0.5812 - accuracy: 0.7923 - val_loss: 0.8267 - val_accuracy: 0.7399 - 192s/epoch - 2s/step\n",
      "Epoch 8/11\n",
      "78/78 - 194s - loss: 0.5253 - accuracy: 0.8149 - val_loss: 0.7988 - val_accuracy: 0.7399 - 194s/epoch - 2s/step\n",
      "Epoch 9/11\n",
      "78/78 - 192s - loss: 0.6031 - accuracy: 0.7883 - val_loss: 0.8762 - val_accuracy: 0.7205 - 192s/epoch - 2s/step\n",
      "Epoch 10/11\n",
      "78/78 - 193s - loss: 0.5902 - accuracy: 0.7826 - val_loss: 0.8141 - val_accuracy: 0.7302 - 193s/epoch - 2s/step\n",
      "20/20 [==============================] - 6s 293ms/step - loss: 0.7988 - accuracy: 0.7399\n",
      "INFO:tensorflow:Assets written to: D:/sam/saved Models/Model 5/Run-7\\assets\n",
      "---- Starting trial : run-8\n",
      "{'filter_size': 7, 'filters_number': 128, 'dense_size': 1024}\n",
      "Epoch 1/11\n",
      "78/78 - 613s - loss: 2.2335 - accuracy: 0.4344 - val_loss: 1.3106 - val_accuracy: 0.5493 - 613s/epoch - 8s/step\n",
      "Epoch 2/11\n",
      "78/78 - 548s - loss: 1.1573 - accuracy: 0.6271 - val_loss: 1.1592 - val_accuracy: 0.5994 - 548s/epoch - 7s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/11\n",
      "78/78 - 649s - loss: 0.9536 - accuracy: 0.6856 - val_loss: 1.1405 - val_accuracy: 0.6123 - 649s/epoch - 8s/step\n",
      "Epoch 4/11\n",
      "78/78 - 383s - loss: 0.8777 - accuracy: 0.7054 - val_loss: 1.0670 - val_accuracy: 0.6462 - 383s/epoch - 5s/step\n",
      "Epoch 5/11\n",
      "78/78 - 381s - loss: 0.8333 - accuracy: 0.7177 - val_loss: 0.9281 - val_accuracy: 0.6882 - 381s/epoch - 5s/step\n",
      "Epoch 6/11\n",
      "78/78 - 771s - loss: 0.7258 - accuracy: 0.7435 - val_loss: 0.8781 - val_accuracy: 0.7076 - 771s/epoch - 10s/step\n",
      "Epoch 7/11\n",
      "78/78 - 450s - loss: 0.6669 - accuracy: 0.7623 - val_loss: 0.8656 - val_accuracy: 0.7060 - 450s/epoch - 6s/step\n",
      "Epoch 8/11\n",
      "78/78 - 551s - loss: 0.5930 - accuracy: 0.7818 - val_loss: 0.8573 - val_accuracy: 0.7173 - 551s/epoch - 7s/step\n",
      "Epoch 9/11\n",
      "78/78 - 623s - loss: 0.5303 - accuracy: 0.8052 - val_loss: 0.9505 - val_accuracy: 0.7027 - 623s/epoch - 8s/step\n",
      "Epoch 10/11\n",
      "78/78 - 698s - loss: 0.5050 - accuracy: 0.8149 - val_loss: 0.9157 - val_accuracy: 0.7496 - 698s/epoch - 9s/step\n",
      "20/20 [==============================] - 28s 431ms/step - loss: 0.8573 - accuracy: 0.7173\n",
      "INFO:tensorflow:Assets written to: D:/sam/saved Models/Model 5/Run-8\\assets\n"
     ]
    }
   ],
   "source": [
    "session_num = 1\n",
    "\n",
    "for filter_size in HP_FILTER_SIZE.domain.values:\n",
    "    for num_filter in HP_NUM_FILTER.domain.values:\n",
    "        for dense_size in HP_DENSE_SIZE.domain.values:\n",
    "        \n",
    "            hparams = {\n",
    "                HP_FILTER_SIZE : filter_size,\n",
    "                HP_NUM_FILTER : num_filter,\n",
    "                HP_DENSE_SIZE: dense_size}\n",
    "\n",
    "            run_name = 'run-%d' %session_num\n",
    "            print('---- Starting trial : %s' % run_name)\n",
    "            print({h.name: hparams[h] for h in hparams})\n",
    "            run('D:/sam/Logs/Model 5/hparam_tuning/' +run_name, hparams, session_num)\n",
    "\n",
    "            session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a model to evaluate on the test set\n",
    "model = tf.keras.models.load_model(r\"D:/sam/saved Models/Model 5/Run-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 7s 294ms/step - loss: 0.7423 - accuracy: 0.7254\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.7423. Test accuracy: 72.54%\n"
     ]
    }
   ],
   "source": [
    "# Printing the test results\n",
    "print('Test loss: {0:.4f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2f44a0e3eb653e60\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2f44a0e3eb653e60\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"D:/sam/Logs/Model 5/hparam_tuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b660e13095d9c51f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b660e13095d9c51f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"D:/sam/Logs/Model 5/fit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
